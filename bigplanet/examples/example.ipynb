{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bigplanet Example\n",
    "\n",
    "David Fleming, July 2016\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, I'll run through the basic functionality of bigplanet, a package for data-processing, analysis, and plotting of data produced by VPLANET.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function, division, absolute_import\n",
    "\n",
    "#Imports\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#Typical plot parameters that make for pretty plots\n",
    "mpl.rcParams['figure.figsize'] = (10,8)\n",
    "mpl.rcParams['font.size'] = 20.0\n",
    "\n",
    "## for Palatino and other serif fonts use:\n",
    "mpl.rc('font',**{'family':'serif','serif':['Computer Modern']})\n",
    "mpl.rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) Import bigplanet\n",
    "\n",
    "---\n",
    "\n",
    "bigplanet, a dumb wordplay on ``big data`` and ``VPLANET``, is a suite of tools used to wrangle and analyze data produced by large-scale ``VPLANET`` simulation suites.  It is currently under active development and any/all suggestions, bug discoveries, pull requests, etc are very much appreciated!\n",
    "\n",
    "bigplanet can be imported and used just like any other python module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bigplanet import data_extraction as de\n",
    "from bigplanet import bigplot as bp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Load in Data\n",
    "\n",
    "---\n",
    "\n",
    "Let's say we ran a simulation where we varied several body parameters in some grid over parameters such as binary semimajor axis, eccentricity and the same for a circumbinary planet (CBP).  The suite of simulations, set up using ``vspace``, produced a lot of directories, one for each simulation, so in order to work with the data products, we need to traverse through each directory, extract the results, and transform them into a meaningful data structure.  \n",
    "\n",
    "Currently, ``bigplanet`` supports extracting data into a python list of dicts or into a hdf5 dataset.  The former is useful for small suites of simulations that can all fit into memory and is pretty fast.  The latter is a versitile compressed file format that allows for quick access of data that cannot fit into memory.  The hdf5 format stores array-like data in a unix-like filetree system that supports random-access by decompressing the given data in real-time.  It's only a factor of a few slower than the all-into-memory approach so I'll default to that for this demo.\n",
    "\n",
    "For more info on all things hdf5, check out these links:\n",
    "\n",
    "hdf5 with python: http://docs.h5py.org/en/latest/quick.html\n",
    "\n",
    "hdf5 general: https://en.wikipedia.org/wiki/Hierarchical_Data_Format (the h, d, and f from hdf5!)\n",
    "\n",
    "hdf5 group: https://www.hdfgroup.org/HDF5/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Tell bigplanet where the data is **\n",
    "\n",
    "---\n",
    "\n",
    "Here, we'll load the data into the variable data.  When using the hdf5 format, data is actually an object that stores metadata about the hdf5 dataset for ease of manipulation.  For this, we must make known the source directory, src, the location of the hdf5 dataset, dataset, and the format we'll be using, fmt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Path to the root directory where all the simulation subdirectories live\n",
    "src = \"/Users/dflemin3/Desktop/GM_run/\"\n",
    "\n",
    "# Define names for archive (for python dict approach not used here)\n",
    "archiveName = src + \"GM_suite.npz\"\n",
    "\n",
    "# Define name for the dataset (hdf5 approach)\n",
    "dataset = src + \"simulation.hdf5\"\n",
    "\n",
    "# Define a data format\n",
    "fmt = \"hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load in the data!**\n",
    "\n",
    "---\n",
    "\n",
    "Here we actually get a data object to manipulate and work with.  This bit of code discriminates between the two formats and prints out useful information.  I should make this into a function.  The core of this \"function\" occurs in the following line\n",
    ">    data = de.extract_data_hdf5(src=src, dataset=dataset)\n",
    "\n",
    "We pass the extract_data_hdf5 function the source directory src and the name of the dataset, dataset.  If the dataset does not exist, i.e. all the data directories in source have not been traversed and parsed, then the function will traverse the simulation directories and store the data into dataset.  On my slow laptop, this takes ~1.5 minutes for ~1000 simulations.  If dataset does exist, it's quickly loaded into data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hdf5 dataset already exists.  Reading from: /Users/dflemin3/Desktop/GM_run/simulation.hdf5\n",
      "Name: /Users/dflemin3/Desktop/GM_run/simulation.hdf5. Size: 625. Order: grid\n"
     ]
    }
   ],
   "source": [
    "if fmt == \"dict\":\n",
    "    if (not os.path.exists(archiveName)):\n",
    "        data = de.extract_data(src)\n",
    "\n",
    "        print(\"Creating archive:\",archiveName)\n",
    "        np.savez(archiveName,data=data)\n",
    "    # Archive exists, load it\n",
    "    else:\n",
    "        print(\"Loading existing archive:\",archiveName)\n",
    "        data = np.load(archiveName)[\"data\"]\n",
    "elif fmt == \"hdf5\":\n",
    "    data = de.extract_data_hdf5(src=src, dataset=dataset, order=\"grid\",compression=\"gzip\")\n",
    "    print(data)\n",
    "else:\n",
    "    print(\"Invalid format:\",fmt)\n",
    "    data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GM_simbe4_ba4_cfe4_ca4'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sim_name(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Data Processing\n",
    "\n",
    "---\n",
    "\n",
    "The real power of this package is the easy of data access and manipulation.  In this section, I'll show the user how to access the results of ``VPLANET`` simulations in a variety of ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Individual simulation data**\n",
    "\n",
    "---\n",
    "\n",
    "Suppose you want to pull the binary (stored in the body \"secondary\") orbital eccentricity and the simulation time from the 2nd (index 1) simulation to plot how it varies as a function of time.  Accessing it is as easy as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: [       0.  1000000.  2000000.  3000000.  4000000.  5000000.  6000000.\n",
      "  7000000.  8000000.  9000000.] ...\n",
      "Ecc: [ 0.01      0.008694  0.007955  0.007777  0.007695  0.007647  0.007616\n",
      "  0.007595  0.00758   0.007569] ...\n"
     ]
    }
   ],
   "source": [
    "time, ecc = data.get(1,\"secondary\",[\"Time\",\"Eccentricity\"])\n",
    "print(\"Time:\",time[0:10],\"...\")\n",
    "print(\"Ecc:\",ecc[0:10],\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "de.data_from_dir_hdf5?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The get method for the data object takes the following arguments:\n",
    "```\n",
    "1) Simulation number : int\n",
    "2) body name : str\n",
    "3) parameter or list of parameters : str, list of str\n",
    "```\n",
    "\n",
    "This method allows for easy data access for individual simulations and allows for one to iterate over an arbitrary number of simulations.  This is useful if, for whatever reason, the user would want to plot binary eccentricity as a function of time from every simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation Notes\n",
    "\n",
    "---\n",
    "\n",
    "Note that by typing\n",
    "\n",
    ">some_bigplanet_func.?\n",
    "\n",
    "into an ipython cell, the docs will appear allowing the user to see what the function does, its input parameters, what they are, what the function returns, etc.  I've taken a lot of time to write out the docs so that the function's arguments and purpose are more clear.  Also, the user can also open up the source file to read further documentation that breaks down what each part of the function is doing.  Alternatively, you can always bug me (David) for an explanation, or to see if even I remember what I wrote."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Bulk Simulation Results**\n",
    "\n",
    "What if we don't want data from individual simulations, but rather some matrix-like structure that shows how one or many parameter changes as a function of initial simulation conditions.  For example, what if one wants to see how the CBP eccentricity at some given time varies as a function of binary a, e and CBP e. \n",
    "\n",
    "To do this, we'll use another function, aggregate_data, that uses the following calling sequence:\n",
    ">de.aggregate_data(data, bodies=bodies, ind=0, funcs={\"cbp\" : {\"Semim\" : np.mean}},\n",
    ">                    new_cols=new_cols,cache=\"cache.pkl\",fmt=fmt,**kw)\n",
    "\n",
    "\n",
    "Instead of actually producing a matrix, this function produces a dictionary of pandas dataframes where the key is the body name and the value is a pandas dataframe where the columns are the parameters varied over the simulation for the given body and any other user-defined columns (I'll discuss this later).\n",
    "\n",
    "This function can get as complex as the user wants it to get, so we'll break it down by input parameter:\n",
    "\n",
    "---\n",
    "\n",
    "1) data\n",
    "``` \n",
    "hdf5 dataset object\n",
    "``` \n",
    "2) bodies\n",
    "```\n",
    "dictionary where the keys are body names and and the values are lists of the initial parameters that were varied for said object.  In our typical example, binary eccentricity was varied in the vspace input file with some line like\n",
    "    secondary.in\n",
    "    dEcc [0.01,0.1,n5] dEcc\n",
    "    \n",
    "In the secondary.in file, eccentricity is outputted by specifying \"Eccentricity\" in the saOutputOrder line.\n",
    "Hence to have that parameter in the final matrix, we would need to include in the bodies dict\n",
    "\n",
    "\"secondary\" : ['Eccentricity']\n",
    "\n",
    "amongst other parameters of interest.  In the cell below our simulation grid spanned binary a, e and the same for the cbp and our bodies dict reflects that.\n",
    "```\n",
    "\n",
    "3) ind\n",
    "```\n",
    "Time index to extract for the given body's variable from each simulation, e.g. the binary's initial (time[ind = 0]) eccentricity.\n",
    "This makes it explicit that we want the matrix to span initial simulation conditions.  I'm not sure why/if a user would have their grid over other time, but this variable allows for that functionality.\n",
    "```\n",
    "\n",
    "4) funcs\n",
    "```\n",
    "Funcs is a nested dictionary of the form {body : {body_variable : function}, body2 : {...}, ...}.  If something in funcs is specified for the variable of a given body, the funcs functionality supercedes the ind behavior and stores the result of funcs of that variable time series instead of the initial condition.  \n",
    "\n",
    "In the example below, I use funcs to store the mean CBP semimajor axis instead of the initial condition.  Typically a user won't use this, but it could be useful.\n",
    "```\n",
    "\n",
    "5) new_cols\n",
    "```\n",
    "New_cols is another nest dictionary that is rather powerful and allows the user to apply any function to the simulation data to produce a new data product for each simulation.  The effect of this is to add another column to the final dataframe.\n",
    "\n",
    "In the example below, I want to add the initial eccentricity again for a trivial example.\n",
    "\n",
    "new_cols = {\"cbp\" : {\"InitEcc\" : trivial}}\n",
    "\n",
    "This tells aggregate_data that for the cbp body, I want a new column, \"InitEcc\", added and it's computed by the trivial function.  Obviously, this functionality becomes useful for non-trivial calculations like computing eccentricity damping times for the cbp.\n",
    "\n",
    "Note that any functions supplied to new_cols require the first 3 parameters to be\n",
    "\n",
    "data, sim, body\n",
    "\n",
    "and require a fmt kwarg. See the docs for more details.\n",
    "```\n",
    "\n",
    "6) kw\n",
    "```\n",
    "A dictionary of any keyword arguments the functions in new_cols require.\n",
    "```\n",
    "\n",
    "7) cache\n",
    "```\n",
    "Where to cache the output of this function into a pickle file.  This is useful if any of your new_cols functions are computationaly expensive and the pickle file can be transfered and read by all sorts of machines and python distros.\n",
    "```\n",
    "\n",
    "8) fmt\n",
    "```\n",
    "Tells the function whether you are using the dict or hdf5 data format.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**\n",
    "\n",
    "---\n",
    "\n",
    "Ok, that's a lot of information, so let's see it in action.  To show off functionality, below I wrote a trivial function that returns the initial eccentricity and takes a keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trivial function to return initial eccentricity\n",
    "# This function assumes an hdf5 format\n",
    "def trivial(data,sim,body,key=None,fmt=\"hdf5\"):\n",
    "    # Check out the get function in action!\n",
    "    return data.get(sim,body,key)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from cache: /Users/dflemin3/Desktop/GM_run/trivial_cache.pkl\n"
     ]
    }
   ],
   "source": [
    "# Define the bodies and body variables to extract using a dictionary\n",
    "bodies = {'cbp': ['Eccentricity', 'SemimajorAxis'],'secondary': ['SemimajorAxis','Eccentricity']}\n",
    "\n",
    "# Define the new value (dataframe column) to produce for a given body.  The new column\n",
    "# and how to calculate it are given as a dictionary for each body.\n",
    "\n",
    "# New column for the cbp is \"InitEcc\" and is calculated using the function \"trivial\"\n",
    "new_cols = {\"cbp\" : {\"InitEcc\" : trivial}}\n",
    "\n",
    "# Define any keyword arguments trivial might need\n",
    "kw = {\"key\" : \"Eccentricity\"}\n",
    "\n",
    "# Extract and save into a cache (or read from it if it already exists)\n",
    "# Note ind=0 makes it clear that we want initial conditions stored for all non-new_cols variables\n",
    "df = de.aggregate_data(data, bodies=bodies, ind=0, funcs={\"cbp\" : {\"SemimajorAxis\" : np.mean}},\n",
    "                    new_cols=new_cols,cache=src+\"trivial_cache.pkl\",fmt=fmt,**kw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** What does df look like?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>InitEcc</th>\n",
       "      <th>SemimajorAxis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038669</td>\n",
       "      <td>0.038669</td>\n",
       "      <td>0.498178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.038107</td>\n",
       "      <td>0.038107</td>\n",
       "      <td>0.672144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.037851</td>\n",
       "      <td>0.037851</td>\n",
       "      <td>0.846260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.037713</td>\n",
       "      <td>0.037713</td>\n",
       "      <td>1.020163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.037632</td>\n",
       "      <td>0.037632</td>\n",
       "      <td>1.194305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Eccentricity   InitEcc  SemimajorAxis\n",
       "0      0.038669  0.038669       0.498178\n",
       "1      0.038107  0.038107       0.672144\n",
       "2      0.037851  0.037851       0.846260\n",
       "3      0.037713  0.037713       1.020163\n",
       "4      0.037632  0.037632       1.194305"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CBP dataframe with new column produced by user-defined function!\n",
    "df[\"cbp\"].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>SemimajorAxis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Eccentricity  SemimajorAxis\n",
       "0          0.01           0.05\n",
       "1          0.01           0.05\n",
       "2          0.01           0.05\n",
       "3          0.01           0.05\n",
       "4          0.01           0.05"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same, but for secondary\n",
    "df[\"secondary\"].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Plotting\n",
    "\n",
    "---\n",
    "\n",
    "Now let's use the dataframe df we created in the section about to generate a summary plot for our simulation suite.  With any large, high-dimensional simulation suite, we'll vary over more parameters than we can neatly plot in a single figure.  Instead of making a confusogram, we'll plot some variable as a function of 2 initial coniditions and marginalize over all other dimensions.  For example, if we want to see how initial CBP eccentricity varies as a function of binary semimajor axis and eccentricity, we'll need to average over other dimensions.  Naturally when marginalizing over other dimensions, the user should ensure that he/she are not losing information in the process.  Below I'll show off two functions that produce the marginalized plots using either matplotlib's imshow or contourf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Shape **\n",
    "\n",
    "Before I get into the plotting functions, I want to introduce the concept of the simulation suite's shape.  In this small test suite, I used vspace to vary binary eccentricity, semimajor axis and the same for the planet in 5 steps.  See the below vspace input file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srcfolder  /usr/lusers/dflemin3/bin/vplanet/examples/binary_hyak\r\n",
      "destfolder /gscratch/stf/dflemin3/vplanet_sims/GM_test\r\n",
      "trialname  GM_sim\r\n",
      "\r\n",
      "file   primary.in\r\n",
      "\r\n",
      "file   secondary.in\r\n",
      "dEcc  [0.01,0.3,n5] be\r\n",
      "dSemi [0.05,0.2,n5] ba\r\n",
      "\r\n",
      "file cbp.in\r\n",
      "dFreeEcc [0.05,0.3,n5] cfe\r\n",
      "dSemi [0.5,1.2,n5] ca\r\n",
      "\r\n",
      "file   vpl.in\r\n"
     ]
    }
   ],
   "source": [
    "! cat /Users/dflemin3/Desktop/GM_run/input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From inspection, we can see that the shape of this dataset is 5 x 5 x 5 x 5.  When using functions that marginalize over other dimensions, the shape must be specified as an interable so the function knows how to compress the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Dims **\n",
    "\n",
    "Similar to shape, the dimensions over which we must marginalize must be known to the function.  This allows the function to know exactly what it must marginalize over.  Dims defaults to -1 (marginalize over the last dimension) but in general is an iterable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Can we plot yet?**\n",
    "\n",
    "Almost.  To use the function, we need to specify a few things.  First, we need x, y and the color variable z.  These are accessed from the dataframe df.  Next, we specify the shape in the manner described above.  Then, we create a figure and axis, if we haven't already, for the plot to live on.  Finally, we have the option of passing the axis labels.  Then plot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Imshow with Gaussian Interpolation **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-bda4966065da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mbp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_red_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bp' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmMAAAHrCAYAAACDw5pVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPSxxZydBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113768b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Init axes labels, data to plot\n",
    "labels = [\"Binary Semimajor Axis [AU]\", \"Binary Eccentricity\", \"Initial CBP Eccentricty\"]\n",
    "x = df[\"secondary\"][\"SemimajorAxis\"]\n",
    "y = df[\"secondary\"][\"Eccentricity\"]\n",
    "z = df[\"cbp\"][\"InitEcc\"]\n",
    "\n",
    "# Shape of the data\n",
    "shape = (5, 5, 5, 5)\n",
    "\n",
    "# Dimensions to compress over\n",
    "dims = (-2, -1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "bp.plot_red_dim(x, y, z, shape, fig, ax, dims=dims, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Contour plot with user-defined number of contours (levels) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Init axes labels, data to plot\n",
    "labels = [\"Binary Semimajor Axis [AU]\", \"Binary Eccentricity\", \"Initial CBP Eccentricty\"]\n",
    "x = df[\"secondary\"][\"SemimajorAxis\"]\n",
    "y = df[\"secondary\"][\"Eccentricity\"]\n",
    "z = df[\"cbp\"][\"Eccentricity\"]\n",
    "\n",
    "# Shape of the data\n",
    "shape = (5, 5, 5, 5)\n",
    "\n",
    "# Dimensions to compress over\n",
    "dims = (-2, -1)\n",
    "\n",
    "# Number of levels for a contour plot\n",
    "levels = 15\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "bp.plot_red_dim_contour(x, y, z, shape, fig, ax, dims=dims, labels=labels, levels=levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
